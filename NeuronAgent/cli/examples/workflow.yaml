# Workflow Definition Example
# This file demonstrates a complete workflow definition

name: data-processing-pipeline
description: Multi-step data processing workflow with error handling

# Workflow Steps
steps:
  - id: extract
    name: Extract Data
    type: sql
    config:
      query: "SELECT * FROM source_table WHERE date > NOW() - INTERVAL '1 day'"
    on_error: stop
  
  - id: transform
    name: Transform Data
    type: code
    depends_on: [extract]
    config:
      language: python
      code: |
        import pandas as pd
        data = pd.DataFrame(input_data)
        # Transform logic here
        transformed = data.groupby('category').sum()
        return transformed.to_dict()
    on_error: retry
    retry_config:
      max_attempts: 3
      backoff: exponential
  
  - id: validate
    name: Validate Results
    type: conditional
    depends_on: [transform]
    config:
      condition: "len(output) > 0"
      on_true: [load]
      on_false: [notify_error]
  
  - id: load
    name: Load to Database
    type: sql
    depends_on: [validate]
    config:
      query: "INSERT INTO target_table VALUES (...)"
  
  - id: notify_success
    name: Send Success Notification
    type: http
    depends_on: [load]
    config:
      url: "https://hooks.slack.com/..."
      method: POST
      body: '{"text": "Pipeline completed successfully"}'
  
  - id: notify_error
    name: Send Error Notification
    type: http
    config:
      url: "https://hooks.slack.com/..."
      method: POST
      body: '{"text": "Pipeline failed"}'

# Workflow Triggers
triggers:
  - type: schedule
    cron: "0 2 * * *"  # Daily at 2 AM
  - type: webhook
    path: /trigger/data-pipeline



