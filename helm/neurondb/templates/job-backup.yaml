{{- if and .Values.backup.enabled (not .Values.neurondb.postgresql.external.enabled) }}
{{- /* Scheduled backup CronJob */}}
apiVersion: batch/v1
kind: CronJob
metadata:
  name: {{ include "neurondb.fullname" . }}-backup
  labels:
    {{- include "neurondb.labels" . | nindent 4 }}
    app.kubernetes.io/component: backup
spec:
  schedule: {{ .Values.backup.schedule | quote }}
  successfulJobsHistoryLimit: {{ .Values.backup.successfulJobsHistoryLimit | default 3 }}
  failedJobsHistoryLimit: {{ .Values.backup.failedJobsHistoryLimit | default 1 }}
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      backoffLimit: 2
      activeDeadlineSeconds: {{ .Values.backup.activeDeadlineSeconds | default 3600 }}
      template:
        metadata:
          labels:
            {{- include "neurondb.labels" . | nindent 12 }}
            app.kubernetes.io/component: backup
        spec:
          serviceAccountName: {{ include "neurondb.neurondb.serviceAccountName" . }}
          restartPolicy: OnFailure
          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
            fsGroup: 1000
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          initContainers:
          - name: wait-for-db
            image: {{ .Values.backup.waitImage.repository }}:{{ .Values.backup.waitImage.tag }}
            command:
            - sh
            - -c
            - |
              until pg_isready -h {{ include "neurondb.postgresHost" . }} -p {{ include "neurondb.postgresPort" . }} -U {{ include "neurondb.postgresUsername" . }}; do
                echo "Waiting for database to be ready..."
                sleep 2
              done
              echo "Database is ready!"
            env:
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ include "neurondb.postgresPasswordSecret" . }}
                  key: {{ include "neurondb.postgresPasswordKey" . }}
          containers:
          - name: backup
            image: {{ .Values.backup.image.repository }}:{{ .Values.backup.image.tag }}
            imagePullPolicy: {{ .Values.backup.image.pullPolicy | default "IfNotPresent" }}
            command:
            - /bin/sh
            - -c
            - |
              set -e
              BACKUP_FILE="neurondb-backup-$(date +%Y%m%d-%H%M%S).dump"
              BACKUP_PATH="/backup/${BACKUP_FILE}"
              
              echo "Starting backup: ${BACKUP_FILE}"
              
              # Create backup using pg_dump with custom format
              if ! pg_dump -h {{ include "neurondb.postgresHost" . }} \
                -p {{ include "neurondb.postgresPort" . }} \
                -U {{ include "neurondb.postgresUsername" . }} \
                -d {{ include "neurondb.postgresDatabase" . }} \
                -Fc \
                -f "${BACKUP_PATH}" \
                -v; then
                echo "ERROR: Failed to create database backup"
                exit 1
              fi
              
              echo "Backup created: ${BACKUP_PATH}"
              BACKUP_SIZE=$(ls -lh "${BACKUP_PATH}" | awk '{print $5}')
              echo "Backup size: ${BACKUP_SIZE}"
              
              # Verify backup file exists and is not empty
              if [ ! -f "${BACKUP_PATH}" ] || [ ! -s "${BACKUP_PATH}" ]; then
                echo "ERROR: Backup file is missing or empty"
                exit 1
              fi
              
              # Upload to S3 if enabled
              {{- if .Values.backup.s3.enabled }}
              echo "Uploading to S3..."
              if ! aws s3 cp "${BACKUP_PATH}" \
                "s3://{{ .Values.backup.s3.bucket }}/{{ .Values.backup.s3.prefix | default "backups" }}/${BACKUP_FILE}" \
                --region {{ .Values.backup.s3.region }}; then
                echo "ERROR: Failed to upload backup to S3"
                exit 1
              fi
              echo "Backup uploaded to S3 successfully"
              
              # Clean up old backups from S3 (keep last N days)
              if [ -n "{{ .Values.backup.retention }}" ]; then
                echo "Cleaning up backups older than {{ .Values.backup.retention }} days..."
                aws s3 ls "s3://{{ .Values.backup.s3.bucket }}/{{ .Values.backup.s3.prefix | default "backups" }}/" \
                  --region {{ .Values.backup.s3.region }} | \
                  while read -r line; do
                    createDate=$(echo $line | awk '{print $1" "$2}')
                    createDate=$(date -d "$createDate" +%s)
                    olderThan=$(date -d "{{ .Values.backup.retention }} days ago" +%s)
                    if [[ $createDate -lt $olderThan ]]; then
                      fileName=$(echo $line | awk '{print $4}')
                      if [[ -n $fileName ]]; then
                        echo "Deleting old backup: $fileName"
                        aws s3 rm "s3://{{ .Values.backup.s3.bucket }}/{{ .Values.backup.s3.prefix | default "backups" }}/$fileName" \
                          --region {{ .Values.backup.s3.region }}
                      fi
                    fi
                  done
              fi
              {{- end }}
              
              # Upload to GCS if enabled
              {{- if .Values.backup.gcs.enabled }}
              echo "Uploading to GCS..."
              if [ ! -f "${GOOGLE_APPLICATION_CREDENTIALS}" ]; then
                echo "ERROR: GCS credentials file not found at ${GOOGLE_APPLICATION_CREDENTIALS}"
                exit 1
              fi
              if ! gsutil cp "${BACKUP_PATH}" \
                "gs://{{ .Values.backup.gcs.bucket }}/{{ .Values.backup.gcs.prefix | default "backups" }}/${BACKUP_FILE}"; then
                echo "ERROR: Failed to upload backup to GCS"
                exit 1
              fi
              echo "Backup uploaded to GCS successfully"
              {{- end }}
              
              # Upload to Azure Blob if enabled
              {{- if .Values.backup.azure.enabled }}
              echo "Uploading to Azure Blob Storage..."
              if [ -n "${AZURE_CLIENT_ID}" ] && [ -n "${AZURE_CLIENT_SECRET}" ] && [ -n "${AZURE_TENANT_ID}" ]; then
                az login --service-principal -u "${AZURE_CLIENT_ID}" -p "${AZURE_CLIENT_SECRET}" --tenant "${AZURE_TENANT_ID}" || true
              fi
              if ! az storage blob upload \
                --account-name {{ .Values.backup.azure.accountName }} \
                --container-name {{ .Values.backup.azure.containerName }} \
                --name "{{ .Values.backup.azure.prefix | default "backups" }}/${BACKUP_FILE}" \
                --file "${BACKUP_PATH}" \
                --auth-mode login; then
                echo "ERROR: Failed to upload backup to Azure Blob Storage"
                exit 1
              fi
              echo "Backup uploaded to Azure Blob Storage successfully"
              {{- end }}
              
              echo "Backup completed successfully!"
            env:
            - name: PGHOST
              value: {{ include "neurondb.postgresHost" . }}
            - name: PGPORT
              value: {{ include "neurondb.postgresPort" . | quote }}
            - name: PGDATABASE
              value: {{ include "neurondb.postgresDatabase" . }}
            - name: PGUSER
              value: {{ include "neurondb.postgresUsername" . }}
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ include "neurondb.postgresPasswordSecret" . }}
                  key: {{ include "neurondb.postgresPasswordKey" . }}
            {{- if .Values.backup.s3.enabled }}
            {{- if and .Values.backup.s3.accessKeyId .Values.backup.s3.secretAccessKey }}
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: {{ include "neurondb.fullname" . }}-backup-credentials
                  key: aws-access-key-id
                  optional: true
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ include "neurondb.fullname" . }}-backup-credentials
                  key: aws-secret-access-key
                  optional: true
            {{- end }}
            - name: AWS_DEFAULT_REGION
              value: {{ .Values.backup.s3.region | quote }}
            {{- end }}
            {{- if .Values.backup.gcs.enabled }}
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: /etc/gcs/credentials.json
            {{- end }}
            {{- if .Values.backup.azure.enabled }}
            - name: AZURE_CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: {{ include "neurondb.fullname" . }}-backup-credentials
                  key: azure-client-id
            - name: AZURE_CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: {{ include "neurondb.fullname" . }}-backup-credentials
                  key: azure-client-secret
            - name: AZURE_TENANT_ID
              valueFrom:
                secretKeyRef:
                  name: {{ include "neurondb.fullname" . }}-backup-credentials
                  key: azure-tenant-id
            {{- end }}
            securityContext:
              allowPrivilegeEscalation: false
              capabilities:
                drop:
                - ALL
              readOnlyRootFilesystem: false
              runAsNonRoot: true
              runAsUser: 1000
              seccompProfile:
                type: RuntimeDefault
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
            {{- if .Values.backup.gcs.enabled }}
            - name: gcs-credentials
              mountPath: /etc/gcs
              readOnly: true
            {{- end }}
            resources:
              {{- toYaml (.Values.backup.resources | default (dict "requests" (dict "memory" "512Mi" "cpu" "500m") "limits" (dict "memory" "2Gi" "cpu" "2"))) | nindent 14 }}
          volumes:
          - name: backup-storage
            {{- if .Values.backup.persistence.enabled }}
            persistentVolumeClaim:
              claimName: {{ include "neurondb.fullname" . }}-backup
            {{- else }}
            emptyDir: {}
            {{- end }}
          {{- if .Values.backup.gcs.enabled }}
          - name: gcs-credentials
            secret:
              secretName: {{ include "neurondb.fullname" . }}-backup-credentials
          {{- end }}
{{- end }}

